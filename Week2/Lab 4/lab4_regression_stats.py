# -*- coding: utf-8 -*-
"""Lab4-Regression stats.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14sD1c6djq6e4KQNXVE39Wh7aRZQKT5dd
"""

# special IPython command to prepare the notebook for matplotlib
# %matplotlib inline 

import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt
import sklearn
import statsmodels.api as sm

import seaborn as sns
sns.set_style("whitegrid")
sns.set_context("poster")

# special matplotlib argument for improved plots
from matplotlib import rcParams

from sklearn.datasets import load_boston
boston = load_boston()

boston.keys()

boston.data.shape

# Print column names
print boston.feature_names

# Print description of Boston housing data set
print boston.DESCR

bos = pd.DataFrame(boston.data)
bos.head()

bos.columns = boston.feature_names
bos.head()

print boston.target.shape

bos['PRICE'] = boston.target
bos.head()

"""## EDA and Summary Statistics
***
"""

bos.describe()

"""### Scatter plots
***

Let's look at some scatter plots for three variables: 'CRIM', 'RM' and 'PTRATIO'. 

Kind of relationships like positive, negative?  linear? non-linear?
"""

plt.scatter(bos.CRIM, bos.PRICE)
plt.xlabel("Per capita crime rate by town (CRIM)")
plt.ylabel("Housing Price")
plt.title("Relationship between CRIM and Price")

plt.scatter(bos.RM, bos.PRICE)
plt.xlabel("Average number of rooms per dwelling (RM)")
plt.ylabel("Housing Price")
plt.title("Relationship between RM and Price")

# sns.regplot(y="PRICE", x="RM", data=bos, fit_reg = True)

# We can also use seaborn regplot for this
#  This provides automatic linear regression fits (useful for data exploration later on)

sns.regplot(y="PRICE", x="RM", data=bos, fit_reg = True)

plt.scatter(bos.PTRATIO, bos.PRICE)
plt.xlabel("Pupil-to-Teacher Ratio (PTRATIO)")
plt.ylabel("Housing Price")
plt.title("Relationship between PTRATIO and Price")

"""### Histograms
***
"""

plt.hist(bos.CRIM)
plt.title("CRIM")
plt.xlabel("Crime rate per capita")
plt.ylabel("Frequencey")
plt.show()

plt.hist(bos.PRICE)
plt.title('Housing Prices: $Y_i$')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()

"""### Method 1 - Linear Regression using `statsmodels`
***
"""

# Import regression modules
# ols - stands for Ordinary least squares, we'll use this
import statsmodels.api as sm
from statsmodels.formula.api import ols

# statsmodels works nicely with pandas dataframes
# The thing inside the "quotes" is called a formula, a bit on that below
m = ols('PRICE ~ RM',bos).fit()
print m.summary()

"""### Linear Regression using `sklearn`"""

from sklearn.linear_model import LinearRegression
X = bos.drop('PRICE', axis = 1)

# This creates a LinearRegression object
lm = LinearRegression()
lm

"""#### LinearRegression Advantages"""

# Look inside linear regression object
# LinearRegression.<tab>

"""Main functions | Description
--- | --- 
`lm.fit()` | Fit a linear model
`lm.predit()` | Predict Y using the linear model with estimated coefficients
`lm.score()` | Returns the coefficient of determination (R^2). *A measure of how well observed outcomes are replicated by the model, as the proportion of total variation of outcomes explained by the model*

#### Output of regression
"""

# Look inside lm object
# lm.<tab>

"""Output | Description
--- | --- 
`lm.coef_` | Estimated coefficients
`lm.intercept_` | Estimated intercept
"""

# Use all 13 predictors to fit linear regression model
lm.fit(X, bos.PRICE)

# your turn
# notice fit_intercept=True and normalize=True
# How would you change the model to not fit an intercept term?

print 'Estimated intercept coefficient:', lm.intercept_

print 'Number of coefficients:', len(lm.coef_)

# The coefficients
pd.DataFrame(zip(X.columns, lm.coef_), columns = ['features', 'estimatedCoefficients'])

# first five predicted prices
lm.predict(X)[0:5]

plt.hist(lm.predict(X))
plt.title('Predicted Housing Prices (fitted values): $\hat{Y}_i$')
plt.xlabel('Price')
plt.ylabel('Frequency')

"""Let's plot the true prices compared to the predicted prices to see they disagree, we saw this exactly befor but this is how you access the predicted values in using `sklearn`."""

# plt.scatter(bos.PRICE, lm.predict(X))
# plt.xlabel("Prices: $Y_i$")
# plt.ylabel("Predicted prices: $\hat{Y}_i$")
# plt.title("Prices vs Predicted Prices: $Y_i$ vs $\hat{Y}_i$")

print np.sum((bos.PRICE - lm.predict(X)) ** 2)

"""#### Mean squared error"""

mseFull = np.mean((bos.PRICE - lm.predict(X)) ** 2)
print mseFull

"""## Relationship between `PTRATIO` and housing price
***
"""

lm = LinearRegression()
lm.fit(X[['PTRATIO']], bos.PRICE)

msePTRATIO = np.mean((bos.PRICE - lm.predict(X[['PTRATIO']])) ** 2)
print msePTRATIO

plt.scatter(bos.PTRATIO, bos.PRICE)
plt.xlabel("Pupil-to-Teacher Ratio (PTRATIO)")
plt.ylabel("Housing Price")
plt.title("Relationship between PTRATIO and Price")

plt.plot(bos.PTRATIO, lm.predict(X[['PTRATIO']]), color='blue', linewidth=3)
plt.show()

X_train = X[:-50]
X_test = X[-50:]
Y_train = bos.PRICE[:-50]
Y_test = bos.PRICE[-50:]
print X_train.shape
print X_test.shape
print Y_train.shape
print Y_test.shape

faithful = sm.datasets.get_rdataset("faithful")

sm.datasets.get_rdataset?
faithful?

faithful.title

faithful = faithful.data
faithful.head()

faithful.shape

"""### Histogram 
***

Histogram of the time between eruptions.
"""

plt.hist(faithful.waiting)
plt.xlabel('Waiting time to next eruption (in mins)')
plt.ylabel('Frequency')
plt.title('Old Faithful Geyser time between eruption')
plt.show()

"""This histogram indicates [Old Faithful isn’t as “faithful”](http://people.stern.nyu.edu/jsimonof/classes/2301/pdf/geystime.pdf).

### Scatter plot 
***

Scatter plot of the `waiting` on the x-axis and the `eruptions` on the y-axis.
"""

plt.scatter(faithful.waiting, faithful.eruptions)
plt.xlabel('Waiting time to next eruption (in mins)')
plt.ylabel('Eruption time (in mins)')
plt.title('Old Faithful Geyser')
plt.show()

X = faithful.waiting
y = faithful.eruptions
model = sm.OLS(y, X)

# Let's look at the options in model
# model.<tab>

results = model.fit()

# Let's look at the options in results
# results.<tab>

print results.summary()

results.params.values

X = sm.add_constant(X)
X.head()

modelW0 = sm.OLS(y, X)
resultsW0 = modelW0.fit()
print resultsW0.summary()

newX = np.array([1,75])
resultsW0.params[0]*newX[0] + resultsW0.params[1] * newX[1]

resultsW0.predict(newX)

"""### The regression line 
***
"""

plt.scatter(faithful.waiting, faithful.eruptions)
plt.xlabel('Waiting time to next eruption (in mins)')
plt.ylabel('Eruption time (in mins)')
plt.title('Old Faithful Geyser')

plt.plot(faithful.waiting, resultsW0.fittedvalues, color='blue', linewidth=3)
plt.show()

resids = faithful.eruptions - resultsW0.predict(X)

resids = resultsW0.resid

plt.plot(faithful.waiting, resids, 'o')
plt.hlines(y = 0, xmin=40, xmax = 100)
plt.xlabel('Waiting time')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()

print np.sum((faithful.eruptions - resultsW0.predict(X)) ** 2)

print np.mean((faithful.eruptions - resultsW0.predict(X)) ** 2)

X = sm.add_constant(faithful.waiting)
y = faithful.eruptions

np.dot(X.T, X)

np.linalg.inv(np.dot(X.T, X))

beta = np.linalg.inv(np.dot(X.T, X)).dot(X.T).dot(y)
print "Directly estimating beta:", beta
print "Estimating beta using statmodels: ", resultsW0.params.values

"""# Method 2 - Logistic Regression
***
"""

from google.colab import files
upload = files.upload()

from IPython.display import Image as Im
from IPython.display import display
Im('shuttle.png')

data = np.array([[float(j) for j in e.strip().split()] for e in open("chall.txt")])
data

# fit logistic regression model
import statsmodels.api as sm
from statsmodels.formula.api import logit, glm, ols

# statsmodels works nicely with pandas dataframes
dat = pd.DataFrame(data, columns = ['Temperature', 'Failure'])
logit_model = logit('Failure ~ Temperature',dat).fit()
print logit_model.summary()

# calculate predicted failure probabilities for new termperatures
x = np.linspace(50, 85, 1000)
p = logit_model.params
eta = p['Intercept'] + x*p['Temperature']
y = np.exp(eta)/(1 + np.exp(eta))

# plot data
temps, pfail = data[:,0], data[:,1]
plt.scatter(temps, pfail)
axes=plt.gca()
plt.xlabel('Temperature')
plt.ylabel('Failure')
plt.title('O-ring failures')

# plot fitted values
plt.plot(x, y)

# change limits, for a nicer plot
plt.xlim(50, 85)
plt.ylim(-0.1, 1.1)